{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86749f7f",
   "metadata": {},
   "source": [
    "Additional notebook for most accurate pinpoint references of words as well as the export to a non-local mongodb collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06456f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T19:12:07.871675Z",
     "start_time": "2023-02-27T19:12:07.527675Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from statistics import mean, median, mode, stdev, variance, pstdev, pvariance\n",
    "from copy import deepcopy, copy\n",
    "from os import listdir\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from pymongo.collation import Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92a6efa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T19:12:07.903673Z",
     "start_time": "2023-02-27T19:12:07.888675Z"
    }
   },
   "outputs": [],
   "source": [
    "#Enter mongodb username, uri of database, and password here\n",
    "user = \"\"\n",
    "uri = \"\"\n",
    "password = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e450cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T19:12:08.181699Z",
     "start_time": "2023-02-27T19:12:08.158703Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_ids(strongs):\n",
    "    \"\"\"Extract the Strong's Concordance ids from\n",
    "       a string representing the extended strongs\n",
    "       of Step Bible data\"\"\"\n",
    "    ids = []\n",
    "    cur_char_index = 0\n",
    "    while (cur_char_index < len(strongs)):\n",
    "        cur_char = strongs[cur_char_index]\n",
    "        if strongs[cur_char_index] == 'H':\n",
    "            hebId = \"\"\n",
    "            cur_char_index += 1\n",
    "            while (cur_char_index < len(strongs)):\n",
    "                cur_char = strongs[cur_char_index]\n",
    "                if cur_char.isnumeric():\n",
    "                    hebId += cur_char\n",
    "                else:\n",
    "                    if hebId.isnumeric():\n",
    "                        ids.append(int(hebId))\n",
    "                        break\n",
    "                cur_char_index += 1\n",
    "        cur_char_index += 1\n",
    "    return ids\n",
    "\n",
    "#Is this necessary? Take out if needed\n",
    "def reduce_strongs(word):\n",
    "    \"\"\"Reduce Step Bible extended Strong's where a proper noun is elaborated\n",
    "        Example: H3470a=יְשַׁעְיָ֫הוּ=Isaiah_§Isaiah@2Ki.19.2 => H3470a=יְשַׁעְיָ֫הוּ=Isaiah_§Isaiah\n",
    "    \"\"\"\n",
    "    at_location = word['strongs'].rfind('@')\n",
    "    if at_location != -1:\n",
    "        word['strongs'] = word['strongs'][:word['strongs'].rindex('@')]\n",
    "\n",
    "\n",
    "def remove_extended_strongs(id_list):\n",
    "    return [item for item in id_list if item <= 8674]\n",
    "\n",
    "\n",
    "def add_strongs_ids(word):\n",
    "    reduce_strongs(word)\n",
    "    ids = extract_ids(word['strongs'])\n",
    "    ids = remove_extended_strongs(ids)\n",
    "    word['ids'] = ids\n",
    "    if len(ids) > 1 and '«' not in word['strongs']:\n",
    "        word['compound'] = True\n",
    "\n",
    "\n",
    "def fuse_ketiv_qere(ketiv, qere, ref_parts):\n",
    "    qere_ref = qere['ref'].replace('-', '.').split('.')\n",
    "    fused = {\n",
    "        \"ref\": qere['ref'][:-2],\n",
    "        \"heb\": {\n",
    "            \"heb_ketiv\": ketiv['heb'],\n",
    "            \"heb_qere\": qere['heb']\n",
    "        },\n",
    "        \"accented\": {\n",
    "            'accented_ketiv': ketiv['accented'],\n",
    "            'accented_qere': qere['accented']\n",
    "        },\n",
    "        \"morph\": {\n",
    "            \"morph_ketiv\": ketiv['morph'],\n",
    "            \"morph_qere\": qere['morph']\n",
    "        },\n",
    "        \"strongs\": {\n",
    "            'strongs_ketiv': ketiv['strongs'],\n",
    "            'strongs_qere': qere['strongs']\n",
    "        },\n",
    "        \"ids\": {\n",
    "            \"ids_ketiv\": ketiv['ids'],\n",
    "            \"ids_qere\": qere['ids']\n",
    "        },\n",
    "        \"ref_obj\": {\n",
    "            \"book\": ref_parts[0],\n",
    "            \"chapter\": ref_parts[1],\n",
    "            \"verse\": ref_parts[2],\n",
    "            \"word\": int(ref_parts[3])\n",
    "        }\n",
    "    }\n",
    "    return fused\n",
    "\n",
    "\n",
    "def create_word(line_parts, ref_parts):\n",
    "    word = {\n",
    "        \"ref\": line_parts[0],\n",
    "        \"heb\": line_parts[1],\n",
    "        \"accented\": line_parts[2],\n",
    "        \"morph\": line_parts[3],\n",
    "        \"strongs\": line_parts[4],\n",
    "        \"ref_obj\": {\n",
    "            \"book\": ref_parts[0],\n",
    "            \"chapter\": ref_parts[1],\n",
    "            \"verse\": ref_parts[2],\n",
    "            \"word\": int(ref_parts[3])\n",
    "        }\n",
    "    }\n",
    "    return word\n",
    "\n",
    "def add_non_cantillation(word):\n",
    "    accented_split = word['accented'].split('/')\n",
    "    longest_part = sorted(accented_split,\n",
    "                          key=lambda item: len(item))[-1]\n",
    "    non_cantillation = ''.join(char for char in longest_part if ord(char) > 0x05AF)\n",
    "    word['non_cantillation'] = non_cantillation\n",
    "\n",
    "def extract_tl_strongs(strongs):\n",
    "    strongs_index = 0\n",
    "    ids = []\n",
    "    while strongs_index < len(strongs):\n",
    "        if strongs[strongs_index] == 'H':\n",
    "            strongs_index += 1\n",
    "            heb_id = \"\"\n",
    "            while strongs_index < len(strongs) and strongs[strongs_index].isnumeric():\n",
    "                heb_id += strongs[strongs_index]\n",
    "                strongs_index += 1\n",
    "            if len(heb_id) != 0:\n",
    "                heb_id = int(heb_id)\n",
    "                if heb_id <= 8674 and heb_id not in ids:\n",
    "                    ids.append(heb_id)\n",
    "        strongs_index += 1\n",
    "    if len(ids) > 1:\n",
    "        ids = ids[1:]\n",
    "    return ids\n",
    "\n",
    "\n",
    "def remove_niqqud(text):\n",
    "    return \"\".join(char for char in text if ord(char) >= 0x05D0)\n",
    "\n",
    "def read_bible_text_file(file_path):\n",
    "    batch_list = []\n",
    "    count = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        prev_word = None\n",
    "        prev_word_index = -1\n",
    "        #Ignore schema\n",
    "        for i in range(3):\n",
    "            file.readline()\n",
    "        for line in file:\n",
    "            line_parts = line.strip().split('\\t')\n",
    "            #Remove KJV Mapping\n",
    "            del line_parts[1]\n",
    "            ref_parts = line_parts[0].replace('-', '.').split('.')\n",
    "            word = create_word(line_parts, ref_parts)\n",
    "            add_strongs_ids(word)\n",
    "            add_non_cantillation(word)\n",
    "            if word['ref'][-1] == 'Q':\n",
    "                word = fuse_ketiv_qere(prev_word, word, ref_parts)\n",
    "                del batch_list[-1]\n",
    "                count += 1\n",
    "            strongs = word['strongs']\n",
    "            if not isinstance(strongs, dict):\n",
    "                word['tls'] = extract_tl_strongs(strongs)\n",
    "\n",
    "            else:\n",
    "                word['tls'] = {\n",
    "                    'tls_ketiv' : extract_tl_strongs(strongs['strongs_ketiv']),\n",
    "                    'tls_qere' : extract_tl_strongs(strongs['strongs_qere'])\n",
    "                }\n",
    "            batch_list.append(word)\n",
    "            prev_word = word\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a525c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T19:12:15.418797Z",
     "start_time": "2023-02-27T19:12:08.613797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 305495 words. Expected value is 305495\n"
     ]
    }
   ],
   "source": [
    "bible_words = []\n",
    "bible_defs = {}\n",
    "bible_parts_location = '../hebrew_sources/stepbible/STEPBible-Data/parts/'\n",
    "\n",
    "with open(f'../definitions/clean_defs.json', 'r', encoding='utf-8') as definitions:\n",
    "    for i, definition in enumerate(definitions, start = 1):\n",
    "        bible_defs[i] = json.loads(definition)\n",
    "        del bible_defs[i]['total_freq']\n",
    "\n",
    "with open('../definitions/book_map.json', 'r', encoding='utf-8') as book_map_file:\n",
    "    book_lookup = json.loads(\"\".join(line.strip() for line in book_map_file))\n",
    "    \n",
    "for bible_part in listdir(bible_parts_location):\n",
    "    bible_words += read_bible_text_file(bible_parts_location + bible_part)\n",
    "\n",
    "print(f'Processed {len(bible_words)} words. Expected value is 305495')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8071c7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T19:12:17.378796Z",
     "start_time": "2023-02-27T19:12:16.629798Z"
    }
   },
   "outputs": [],
   "source": [
    "def insert_ref(tls_id, ref):\n",
    "    definition = bible_defs[tls_id]\n",
    "    book, chapter, verse, word = ref.values()\n",
    "    if 'refs' not in definition:\n",
    "        definition['refs'] = {book: {chapter: {verse: [word]}}}\n",
    "        definition['frequency'] = 1\n",
    "        return\n",
    "    refs = definition['refs']\n",
    "    if book not in refs:\n",
    "        refs[book] = {chapter: {verse: [word]}}\n",
    "    elif chapter not in refs[book]:\n",
    "        refs[book][chapter] = {verse: [word]}\n",
    "    elif verse not in refs[book][chapter]:\n",
    "        refs[book][chapter][verse] = [word]\n",
    "    else:\n",
    "        refs[book][chapter][verse].append(word)\n",
    "    definition['frequency'] += 1\n",
    "    \n",
    "for word in bible_words:\n",
    "    tls = word['tls']\n",
    "    ref = word['ref_obj']\n",
    "    if not isinstance(tls, dict):\n",
    "        for tls_id in tls:\n",
    "            insert_ref(tls_id, ref)\n",
    "    else:\n",
    "        ketiv_ids, qere_ids = tls.values()\n",
    "        for tls_id in ketiv_ids:\n",
    "            insert_ref(tls_id, ref)\n",
    "        if ketiv_ids != qere_ids:\n",
    "            for tls_id in qere_ids:\n",
    "                insert_ref(tls_id, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a52a5aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T19:12:18.831796Z",
     "start_time": "2023-02-27T19:12:18.770799Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(bible_defs) + 1):\n",
    "    variants = set()\n",
    "    definition = bible_defs[i]\n",
    "    for variant in definition['variants']:\n",
    "        niqqud = variant['niqqud']\n",
    "        variants.add(niqqud)\n",
    "    definition['variants'] = list(variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdc3ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T04:43:26.316362Z",
     "start_time": "2023-02-22T04:43:25.961060Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../definitions/hebrew_reference.json', 'w', encoding='utf-8') as dictionary:\n",
    "    for item in bible_defs.values():\n",
    "        dictionary.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503995e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T04:18:49.702119Z",
     "start_time": "2023-02-22T04:18:49.021736Z"
    }
   },
   "outputs": [],
   "source": [
    "conn_str = \"mongodb+srv://{}:{}@{}/?retryWrites=true&w=majority\".format(user, password, uri)\n",
    "client = MongoClient(conn_str, server_api=ServerApi('1'))\n",
    "try:\n",
    "    print(client.server_info())\n",
    "except Exception:\n",
    "    print(\"Unable to connect to server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d71e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T05:21:05.997906Z",
     "start_time": "2023-02-16T05:21:05.953907Z"
    }
   },
   "outputs": [],
   "source": [
    "databases = client.list_database_names()\n",
    "print(f'These are the databases: {databases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f71a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T05:21:06.012858Z",
     "start_time": "2023-02-16T05:21:05.998906Z"
    }
   },
   "outputs": [],
   "source": [
    "db = client.dictionaries\n",
    "collection = db.hebrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce0c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T05:21:06.028604Z",
     "start_time": "2023-02-16T05:21:06.013859Z"
    }
   },
   "outputs": [],
   "source": [
    "defs_list = list(bible_defs.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
